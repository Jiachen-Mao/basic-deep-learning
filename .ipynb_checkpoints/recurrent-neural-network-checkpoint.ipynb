{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural network implemented in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mnist import MNIST\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (60000, 784)\n",
      "Training label shape: (60000,)\n",
      "Testing set shape: (10000, 784)\n",
      "Testing label shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "path_to_data = os.getcwd() + os.path.expanduser('\\\\MNIST_data')\n",
    "mndata = MNIST(path_to_data)\n",
    "\n",
    "x_train, y_train = mndata.load_training()\n",
    "x_test, y_test = mndata.load_testing()\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(f'Training set shape: {x_train.shape}')\n",
    "print(f'Training label shape: {y_train.shape}')\n",
    "print(f'Testing set shape: {x_test.shape}')\n",
    "print(f'Testing label shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify hyper-parameters and one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = 0.01\n",
    "n_epoch = 4\n",
    "n_input = 28\n",
    "n_class = 10\n",
    "batch_size = 100\n",
    "n_train_sample = x_train.shape[0]\n",
    "n_test_sample = x_test.shape[0]\n",
    "\n",
    "n_train_batch = n_train_sample // batch_size\n",
    "n_test_batch = n_test_sample // batch_size\n",
    "\n",
    "n_hidden = 50\n",
    "n_layer = 3\n",
    "n_step = 28\n",
    "\n",
    "y_train_one_hot = np.zeros((n_train_sample, n_class))\n",
    "y_train_one_hot[np.arange(n_train_sample), y_train] = 1\n",
    "\n",
    "y_test_one_hot = np.zeros((n_test_sample, n_class))\n",
    "y_test_one_hot[np.arange(n_test_sample), y_test] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cell():\n",
    "    cell = tf.contrib.rnn.LSTMCell(num_units = n_hidden)\n",
    "    return cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\maoja\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-4-350f49b3c020>:2: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-5-370ded9f2a8b>:11: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-5-370ded9f2a8b>:16: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Create placeholder variables for the input and target\n",
    "X_placeholder = tf.placeholder(tf.float32, shape = [batch_size, n_step, n_input])\n",
    "y_placeholder = tf.placeholder(tf.int32, shape = [batch_size, n_class])\n",
    "\n",
    "# Create placeholder variables for final weight and bias matrix\n",
    "V = tf.Variable(tf.random_normal(shape = [n_hidden, n_class]))\n",
    "c = tf.Variable(tf.random_normal(shape = [n_class]))\n",
    "\n",
    "cell = tf.contrib.rnn.MultiRNNCell([make_cell() for _ in range(n_layer)], state_is_tuple = True)\n",
    "\n",
    "init_state = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "# Create an RNN specified by \"cell,\" i.e., unroll the network\n",
    "output, final_state = tf.nn.dynamic_rnn(cell, X_placeholder, initial_state = init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = tf.transpose(output, [1,0,2])\n",
    "last_output = tf.gather(temp, int(temp.get_shape()[0] - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\maoja\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "logit = tf.matmul(last_output, V) + c\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = y_placeholder, logits = logit))\n",
    "train_step = tf.train.AdamOptimizer(rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logit, 1), tf.argmax(y_placeholder, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Minibatch loss: 2.882    Accuracy: 0.120\n",
      "Minibatch loss: 0.285    Accuracy: 0.930\n",
      "Minibatch loss: 0.200    Accuracy: 0.950\n",
      "Minibatch loss: 0.142    Accuracy: 0.950\n",
      "Minibatch loss: 0.125    Accuracy: 0.950\n",
      "Minibatch loss: 0.084    Accuracy: 0.960\n",
      "\n",
      "Epoch: 1\n",
      "Minibatch loss: 0.195    Accuracy: 0.940\n",
      "Minibatch loss: 0.142    Accuracy: 0.960\n",
      "Minibatch loss: 0.181    Accuracy: 0.950\n",
      "Minibatch loss: 0.117    Accuracy: 0.960\n",
      "Minibatch loss: 0.077    Accuracy: 0.970\n",
      "Minibatch loss: 0.064    Accuracy: 0.990\n",
      "\n",
      "Epoch: 2\n",
      "Minibatch loss: 0.161    Accuracy: 0.950\n",
      "Minibatch loss: 0.143    Accuracy: 0.970\n",
      "Minibatch loss: 0.048    Accuracy: 1.000\n",
      "Minibatch loss: 0.125    Accuracy: 0.960\n",
      "Minibatch loss: 0.030    Accuracy: 0.990\n",
      "Minibatch loss: 0.133    Accuracy: 0.980\n",
      "\n",
      "Epoch: 3\n",
      "Minibatch loss: 0.062    Accuracy: 0.980\n",
      "Minibatch loss: 0.180    Accuracy: 0.950\n",
      "Minibatch loss: 0.027    Accuracy: 0.990\n",
      "Minibatch loss: 0.025    Accuracy: 1.000\n",
      "Minibatch loss: 0.021    Accuracy: 1.000\n",
      "Minibatch loss: 0.022    Accuracy: 1.000\n",
      "\n",
      "Testing...\n",
      "\n",
      "Average loss on test set: 0.027\n",
      "Accuracy on test set: 0.990\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Training\n",
    "    for epoch in range(n_epoch):\n",
    "        print()\n",
    "        print(f'Epoch: {epoch}')\n",
    "        \n",
    "        for i in range(n_train_batch):\n",
    "            start = i * batch_size\n",
    "            end = (i + 1) * batch_size\n",
    "            \n",
    "            x_batch = x_train[start:end]\n",
    "            x_batch = x_batch.reshape((batch_size, n_step, n_input))\n",
    "            y_batch = y_train_one_hot[start:end]\n",
    "            \n",
    "            _train_step = sess.run(train_step,\n",
    "                                  feed_dict = {\n",
    "                                      X_placeholder: x_batch,\n",
    "                                      y_placeholder:y_batch\n",
    "                                  })\n",
    "            if i % 100 == 0:\n",
    "                _loss, _accuracy = sess.run([loss, accuracy],\n",
    "                                           feed_dict = {\n",
    "                                               X_placeholder:x_batch,\n",
    "                                               y_placeholder:y_batch\n",
    "                                           })\n",
    "                print(f'Minibatch loss: {_loss:.3f}    '\n",
    "                     f'Accuracy: {_accuracy:.3f}')\n",
    "    \n",
    "    print()\n",
    "    print('Testing...')\n",
    "    \n",
    "    \n",
    "    # Testing\n",
    "    losses = []\n",
    "    acc = []\n",
    "    \n",
    "    for i in range(n_test_batch):\n",
    "        start = i * batch_size\n",
    "        end = (i + 1) * batch_size\n",
    "        \n",
    "        x_test_batch = x_test[start:end]\n",
    "        x_test_batch = x_test_batch.reshape((batch_size, n_step, n_input))\n",
    "        y_test_batch = y_test_one_hot[start:end]\n",
    "        \n",
    "        test_loss, test_acc, _train_step = sess.run([loss, accuracy, train_step],\n",
    "                                                   feed_dict = {\n",
    "                                                       X_placeholder:x_test_batch,\n",
    "                                                       y_placeholder:y_test_batch\n",
    "                                                   })\n",
    "        losses.append(test_loss)\n",
    "        acc.append(test_acc)\n",
    "    \n",
    "    print()\n",
    "    print(f\"Average loss on test set: {np.mean(test_loss):.3f}\")\n",
    "    print(f\"Accuracy on test set: {np.mean(test_acc):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
